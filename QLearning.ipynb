{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QLearning-11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDPPZPcXaW1X",
        "colab_type": "code",
        "outputId": "ebc238c4-87c1-4561-ed3a-14a752ef1d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "from gym.envs.registration import register\n",
        "register(\n",
        "    id='Deterministic-4x4-FrozenLake-v0', #new environment\n",
        "    entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', \n",
        "    kwargs={'map_name': '4x4', 'is_slippery': False} # argument passed to the env\n",
        ")\n",
        "env = gym.make('Deterministic-4x4-FrozenLake-v0')\n",
        "my_desk = [\n",
        "    \"GFFFF\",\n",
        "    \"FFFFF\",\n",
        "    \"FFFFG\",\n",
        "    \"FFFFF\",\n",
        "    \"FGFFG\"\n",
        "]\n",
        " \n",
        "\n",
        "\n",
        "import gym\n",
        "\n",
        "class CustomizedFrozenLake(gym.envs.toy_text.frozen_lake.FrozenLakeEnv):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CustomizedFrozenLake, self).__init__(**kwargs)\n",
        "\n",
        "        for state in range(self.nS): # for all states\n",
        "            for action in range(self.nA): # for all actions\n",
        "                my_transitions = []\n",
        "                for (prob, next_state, _, is_terminal) in self.P[state][action]:\n",
        "                    row = next_state // self.ncol\n",
        "                    col = next_state - row * self.ncol\n",
        "                    tile_type = self.desc[row, col]\n",
        "                    if tile_type == b'F':\n",
        "                        reward = -1\n",
        "                    elif tile_type == b'G':\n",
        "                        reward = 10\n",
        "                    #else:\n",
        "                        #reward = 0\n",
        "\n",
        "                    my_transitions.append((prob, next_state, reward, is_terminal))\n",
        "                self.P[state][action] = my_transitions\n",
        "\n",
        "from gym.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id='Stochastic-5x5-FrozenLake-v0',\n",
        "    entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv',\n",
        "    kwargs={'desc': my_desk, 'is_slippery': False})\n",
        "env = gym.make('Stochastic-5x5-FrozenLake-v0')\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mG\u001b[0mFFFF\n",
            "FFFFF\n",
            "FFFFG\n",
            "FFFFF\n",
            "FGFFG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/toy_text/frozen_lake.py:112: RuntimeWarning: invalid value encountered in true_divide\n",
            "  isd /= isd.sum()\n",
            "/usr/local/lib/python3.6/dist-packages/gym/envs/toy_text/discrete.py:13: RuntimeWarning: invalid value encountered in greater\n",
            "  return (csprob_n > np_random.rand()).argmax()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6pgHPwdaiaL",
        "colab_type": "code",
        "outputId": "42c0a686-86e6-4384-c90d-20ee6c6c5c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "env.reset()\n",
        "env.render()\n",
        "\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mG\u001b[0mFFFF\n",
            "FFFFF\n",
            "FFFFG\n",
            "FFFFF\n",
            "FGFFG\n",
            "Action Space Discrete(4)\n",
            "State Space Discrete(25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/toy_text/discrete.py:13: RuntimeWarning: invalid value encountered in greater\n",
            "  return (csprob_n > np_random.rand()).argmax()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgAG6QjOamz_",
        "colab_type": "code",
        "outputId": "348bf6c2-ccae-40a7-b5ce-a72f0fb234fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "\"\"\"ACTIONS DEFINED VIA:\n",
        "    0 = SOUTH\n",
        "    1 = NORTH\n",
        "    2 = EAST\n",
        "    3 = WEST\n",
        "\"\"\"\n",
        "\n",
        "state=env.s \n",
        "if state in range (0,14):\n",
        "  print(\"State:\", state)\n",
        "elif state in range (14,20):\n",
        "  print(\"State:\", state+1)  \n",
        "elif state in range (20,22):\n",
        "  print(\"State:\", state+2)\n",
        "\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State: 0\n",
            "\n",
            "\u001b[41mG\u001b[0mFFFF\n",
            "FFFFF\n",
            "FFFFG\n",
            "FFFFF\n",
            "FGFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ISFDm45am3I",
        "colab_type": "code",
        "outputId": "7b6759ba-1f5c-4f9d-c68d-bb21c674ef41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "env.P[state][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 0, 0, True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sFFaTUTbQFw",
        "colab_type": "code",
        "outputId": "4fd829d9-2905-4ad2-ee5a-d137ed83e98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "m=int(input(\"Enter State numnber for start:\"))\n",
        "\n",
        "if m in range (0,14):\n",
        "  env.s = m \n",
        "elif m in range (14,20):\n",
        "  env.s = m+1\n",
        "elif m in range (20,22):\n",
        "  env.s = m+2\n",
        " # set environment to illustration's state\n",
        "env.render()\n",
        "\n",
        "print(\"....................Learning Starts........................\")\n",
        "\n",
        "epochs = 0\n",
        "penalties, reward = 0, 0\n",
        "\n",
        "frames = [] # for animation\n",
        "\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "    if reward == -1:\n",
        "        penalties += 1\n",
        "    \n",
        "    # Put each rendered frame into dict for animation\n",
        "    frames.append({\n",
        "        'frame' : env.render(mode='human'),\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward\n",
        "        }\n",
        "    )\n",
        "\n",
        "    epochs += 1\n",
        "    \n",
        "    \n",
        "print(\"Timesteps taken: {}\".format(epochs))\n",
        "print(\"Penalties incurred: {}\".format(penalties))\n",
        "print(\"\\n\")\n",
        "print(frames)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter State numnber for start:14\n",
            "\n",
            "GFFFF\n",
            "FFFFF\n",
            "FFFFG\n",
            "\u001b[41mF\u001b[0mFFFF\n",
            "FGFFG\n",
            "....................Learning Starts........................\n",
            "  (Down)\n",
            "GFFFF\n",
            "FFFFF\n",
            "FFFFG\n",
            "FFFFF\n",
            "\u001b[41mF\u001b[0mGFFG\n",
            "  (Right)\n",
            "GFFFF\n",
            "FFFFF\n",
            "FFFFG\n",
            "FFFFF\n",
            "F\u001b[41mG\u001b[0mFFG\n",
            "Timesteps taken: 2\n",
            "Penalties incurred: 0\n",
            "\n",
            "\n",
            "[{'frame': None, 'state': 20, 'action': 1, 'reward': 0.0}, {'frame': None, 'state': 21, 'action': 2, 'reward': 1.0}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QU1OHkubQJJ",
        "colab_type": "code",
        "outputId": "618de6bc-1895-4a8d-fdc5-1d93d509eba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(\"frame: \",frame)\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        #print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(.1)\n",
        "        \n",
        "print_frames(frames)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frame:  {'frame': None, 'state': 24, 'action': 2, 'reward': 1.0}\n",
            "Timestep: 1\n",
            "Action: 2\n",
            "Reward: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydp43wHQam54",
        "colab_type": "code",
        "outputId": "5ebb24b8-200b-4c62-e73d-57b6f55d2e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "\"\"\"QLearning\"\"\"\n",
        "import numpy as np\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "print(q_table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjmVecZCam8p",
        "colab_type": "code",
        "outputId": "3c6cc164-d74c-403c-d6dd-f4f978da931f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "%%time\n",
        "#Training the Agent\n",
        "\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "\n",
        "# For plotting metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "for i in range(1, 10001):\n",
        "    state = env.reset()\n",
        "\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample() # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state]) # Exploit learned values\n",
        "\n",
        "        next_state, reward, done, info = env.step(action) \n",
        "        \n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "        \n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value\n",
        "\n",
        "        if reward == -1:\n",
        "            penalties += 1\n",
        "\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "        \n",
        "    if i % 100 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episode: {i}\")\n",
        "\n",
        "print(\"Training finished.\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 100000\n",
            "Training finished.\n",
            "\n",
            "CPU times: user 7.5 s, sys: 2.33 s, total: 9.83 s\n",
            "Wall time: 9.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8w80yJLftec",
        "colab_type": "code",
        "outputId": "0bf072fd-0343-4b7d-f016-43878487171b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "m=int(input(print(\"Enter state value:\")))\n",
        "\n",
        "\n",
        "for m in range (0,14):\n",
        "  print(q_table[m])\n",
        "for m in range (14,20):\n",
        "  print(q_table[(m+1)])\n",
        "for m in range (20,22):\n",
        "  print(q_table[(m+2)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter state value:\n",
            "20\n",
            "[0. 0. 0. 0.]\n",
            "[1.   0.36 0.36 0.6 ]\n",
            "[0.6        0.21599983 0.21599977 0.35999992]\n",
            "[0.35999997 0.03954002 0.01053266 0.0582606 ]\n",
            "[0.08836117 0.         0.         0.        ]\n",
            "[0.59999976 0.35999989 0.35999997 1.        ]\n",
            "[0.6        0.2159974  0.21599977 0.59999917]\n",
            "[0.36       0.02348849 0.02607496 0.0684    ]\n",
            "[0.16088968 0.         0.         0.        ]\n",
            "[0. 0. 0. 0.]\n",
            "[0.26911731 0.09340281 0.10309805 0.6       ]\n",
            "[0.35999985 0.00175724 0.02009013 0.036     ]\n",
            "[0.15117515 0.         0.         0.        ]\n",
            "[0.00815816 0.         0.         0.        ]\n",
            "[0.01549376 0.         0.         0.29322828]\n",
            "[0.03047873 0.         0.         0.        ]\n",
            "[0. 0. 0. 0.]\n",
            "[0. 0. 0. 0.]\n",
            "[0. 0. 0. 0.]\n",
            "[0. 0. 0. 0.]\n",
            "[0. 0. 0. 0.]\n",
            "[0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'q_table[20]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx83_zhfj2DQ",
        "colab_type": "code",
        "outputId": "dfd35e74-779f-40dc-96b0-f1847e1c27f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "q_table[20] #Checking Qvalue for any random state"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLOgBUvxfthR",
        "colab_type": "code",
        "outputId": "bb4c8749-38ec-471d-ac2b-a5d83bb59c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "\"\"\"Evaluating Agent's performance after Q-learning\"\"\"\n",
        "\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 520148\n",
        "\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    \n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        if reward == -1:\n",
        "            penalties += 1\n",
        "\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results after 520148 episodes:\n",
            "Average timesteps per episode: 1.0\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyp_1tZtftkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}